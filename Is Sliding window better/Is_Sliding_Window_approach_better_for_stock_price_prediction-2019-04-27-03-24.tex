%%
%% Copyright 2007, 2008, 2009 Elsevier Ltd
%%
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%%
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%%
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%%
\documentclass[5p,,preprint,12pt,twocolumn]{elsarticle}
\makeatletter\if@twocolumn\PassOptionsToPackage{switch}{lineno}\else\fi\makeatother


\usepackage{tabulary,xcolor}
\usepackage{amsfonts,amsmath,amssymb}
\usepackage[T1]{fontenc}
\makeatletter
\let\save@ps@pprintTitle\ps@pprintTitle
\def\ps@pprintTitle{\save@ps@pprintTitle\gdef\@oddfoot{\footnotesize\itshape \null\hfill\today}}
\def\hlinewd#1{%
  \noalign{\ifnum0=`}\fi\hrule \@height #1%
  \futurelet\reserved@a\@xhline}
\def\tbltoprule{\hlinewd{.8pt}\\[-12pt]}
\def\tblbottomrule{\noalign{\vspace*{6pt}}\hline\noalign{\vspace*{2pt}}}
\def\tblmidrule{\noalign{\vspace*{6pt}}\hline\noalign{\vspace*{2pt}}}
\AtBeginDocument{\ifNAT@numbers \biboptions{sort&compress}\fi}
\makeatother

  


\usepackage{ifluatex}
\ifluatex
\usepackage{fontspec}
\defaultfontfeatures{Ligatures=TeX}
\usepackage[]{unicode-math}
\unimathsetup{math-style=TeX}
\else 
\usepackage[utf8]{inputenc}
\fi 
\ifluatex\else\usepackage{stmaryrd}\fi

  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Following additional macros are required to function some 
% functions which are not available in the class used.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{url,multirow,morefloats,floatflt,cancel,tfrupee}
\makeatletter


\AtBeginDocument{\@ifpackageloaded{textcomp}{}{\usepackage{textcomp}}}
\makeatother
\usepackage{colortbl}
\usepackage{xcolor}
\usepackage{pifont}
\usepackage[nointegrals]{wasysym}
\urlstyle{rm}
\makeatletter

%%%For Table column width calculation.
\def\mcWidth#1{\csname TY@F#1\endcsname+\tabcolsep}

%%Hacking center and right align for table
\def\cAlignHack{\rightskip\@flushglue\leftskip\@flushglue\parindent\z@\parfillskip\z@skip}
\def\rAlignHack{\rightskip\z@skip\leftskip\@flushglue \parindent\z@\parfillskip\z@skip}

%Etal definition in references
\@ifundefined{etal}{\def\etal{\textit{et~al}}}{}


%\if@twocolumn\usepackage{dblfloatfix}\fi
\usepackage{ifxetex}
\ifxetex\else\if@twocolumn\@ifpackageloaded{stfloats}{}{\usepackage{dblfloatfix}}\fi\fi

\AtBeginDocument{
\expandafter\ifx\csname eqalign\endcsname\relax
\def\eqalign#1{\null\vcenter{\def\\{\cr}\openup\jot\m@th
  \ialign{\strut$\displaystyle{##}$\hfil&$\displaystyle{{}##}$\hfil
      \crcr#1\crcr}}\,}
\fi
}

%For fixing hardfail when unicode letters appear inside table with endfloat
\AtBeginDocument{%
  \@ifpackageloaded{endfloat}%
   {\renewcommand\efloat@iwrite[1]{\immediate\expandafter\protected@write\csname efloat@post#1\endcsname{}}}{\newif\ifefloat@tables}%
}%

\def\BreakURLText#1{\@tfor\brk@tempa:=#1\do{\brk@tempa\hskip0pt}}
\let\lt=<
\let\gt=>
\def\processVert{\ifmmode|\else\textbar\fi}
\let\processvert\processVert

\@ifundefined{subparagraph}{
\def\subparagraph{\@startsection{paragraph}{5}{2\parindent}{0ex plus 0.1ex minus 0.1ex}%
{0ex}{\normalfont\small\itshape}}%
}{}

% These are now gobbled, so won't appear in the PDF.
\newcommand\role[1]{\unskip}
\newcommand\aucollab[1]{\unskip}
  
\@ifundefined{tsGraphicsScaleX}{\gdef\tsGraphicsScaleX{1}}{}
\@ifundefined{tsGraphicsScaleY}{\gdef\tsGraphicsScaleY{.9}}{}
% To automatically resize figures to fit inside the text area
\def\checkGraphicsWidth{\ifdim\Gin@nat@width>\linewidth
	\tsGraphicsScaleX\linewidth\else\Gin@nat@width\fi}

\def\checkGraphicsHeight{\ifdim\Gin@nat@height>.9\textheight
	\tsGraphicsScaleY\textheight\else\Gin@nat@height\fi}

\def\fixFloatSize#1{}%\@ifundefined{processdelayedfloats}{\setbox0=\hbox{\includegraphics{#1}}\ifnum\wd0<\columnwidth\relax\renewenvironment{figure*}{\begin{figure}}{\end{figure}}\fi}{}}
\let\ts@includegraphics\includegraphics

\def\inlinegraphic[#1]#2{{\edef\@tempa{#1}\edef\baseline@shift{\ifx\@tempa\@empty0\else#1\fi}\edef\tempZ{\the\numexpr(\numexpr(\baseline@shift*\f@size/100))}\protect\raisebox{\tempZ pt}{\ts@includegraphics{#2}}}}

%\renewcommand{\includegraphics}[1]{\ts@includegraphics[width=\checkGraphicsWidth]{#1}}
\AtBeginDocument{\def\includegraphics{\@ifnextchar[{\ts@includegraphics}{\ts@includegraphics[width=\checkGraphicsWidth,height=\checkGraphicsHeight,keepaspectratio]}}}

\DeclareMathAlphabet{\mathpzc}{OT1}{pzc}{m}{it}

\def\URL#1#2{\@ifundefined{href}{#2}{\href{#1}{#2}}}

%%For url break
\def\UrlOrds{\do\*\do\-\do\~\do\'\do\"\do\-}%
\g@addto@macro{\UrlBreaks}{\UrlOrds}



\edef\fntEncoding{\f@encoding}
\def\EUoneEnc{EU1}
\makeatother
\def\floatpagefraction{0.8} 
\def\dblfloatpagefraction{0.8}
\def\style#1#2{#2}
\def\xxxguillemotleft{\fontencoding{T1}\selectfont\guillemotleft}
\def\xxxguillemotright{\fontencoding{T1}\selectfont\guillemotright}

\newif\ifmultipleabstract\multipleabstractfalse%
\newenvironment{typesetAbstractGroup}{}{}%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\emergencystretch 20pt \tolerance = 1500 \def\floatpagefraction{0.8}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Feature enabled:
%text-layout: twocolumn
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{float}

\begin{document}



\begin{frontmatter}
	
\title{Is Sliding Window approach better for stock price prediction?
}
    
\author[]{Ankit Thakkar\corref{c-1fe21d74d925}}
\ead{ankit.thakkar@nirmauni.ac.in}\cortext[c-1fe21d74d925]{Corresponding author.}
\author[]{Mufaddal Naya}
\ead{17bit055@nirmauni.ac.in}
    

\begin{abstract}
With proper knowledge of any companies stock and insight, one can gain large profit sitting at home. Stock market of a company is a time series data and stock price prediction is one of the field where many researchers had gathered interest to predict the stock prices or trend in future using historical data and technical indicator with high accuracy. A good prediction model of a stock's future price will increase trader's profits. In this report, the proposed model uses deep learning model LSTM {\textemdash} Long short-term memory to predict the stock trend with two different approaches, with and without using a sliding windowand comparing there results.

\textbf{Index Terms}{\textendash} \textbf{Long Short Term Memory}, Historical Data, Sliding window approach, Technical Indicators and Stock price Prediction.
\end{abstract}
\end{frontmatter}
    
\section{Introduction}
Stock price prediction is a topic that attracts many data researchers and data analytics as a good stock prediction can capitulate notable profit. Stock of a company cannot just be predicted easily. Stock market is volatile, haywire, uncertain and non-linear data \unskip~\cite{490201:11043943}. The stock price of any given company is very much uncertain. Finding patterns in these stocks is a very difficult task. The random change in the stock market is referred as random-walk behavior of stock prices with time by \unskip~\cite{490201:11043765}. This statement holds very much true as there are many uncertain factors as if the country's progress, any natural disaster or the political status of the country.

To predict the stock of some data we need to find some pattern in the stock chart using the raw data or extracting some of the useful Technical Indicators. Firstly, for prediction of any stock price, we need to analyze the data. For analysis, two approaches are used Fundamental and Technical indicators used to forecast stock prices. Fundamental analysis usually deals with the cause of the market, it takes all the macro economic factors such as the company's growth the climate etc to predict the trend of the future stocks. Technical analysis uses stock charts to analyze the patterns in the stock price. They are derived from the raw data using mathematical formulas. After analyzing the data various linear and non-linear models are being used to predict the data like ARIMA (auto regressive model) and ANNs. 

Artificial Neural networks like RNN, CNN, and LSTM are commonly used model in stock price prediction \unskip~\cite{490201:11043807}. ANN was inspired from function of human brain and implementing a complex network of neurons.  In \unskip~\cite{490201:11043808}, they proposed a fusion model implementing HMM, ANN and GA for predicting stock price. These Models are widely used in areas like Image Processing, Natural Language Processing, Time Series Analysis, etc. Over-fitting and under-fitting of data is a big problem while using ANN model for stock price prediction \unskip~\cite{490201:11043809}. ANNs are very useful for short term forecasting. While non-linear model are better choice to predict stocks, many factual researchers had shown that non- linear models might not outperform linear models every time \unskip~\cite{490201:11043810}\unskip~\cite{490201:11043811}\unskip~\cite{490201:11043812}. Recently in \unskip~\cite{490201:11043813}, they tried to compare linear model with nonlinear model and tried to find the accuracy, which shows how the nonlinear model outperform linear model. The linear model in the comparison was ARIMA whereas the nonlinear model were GRU and LSTM in which the LSTM outperform every other model. Also in \unskip~\cite{490201:11043814}, they tried to predict the effect of demonetization on stocks of seven Indian companies CNX, NIFTY50. ANN were used to predict the future values of these stocks. \unskip~\cite{490201:11043815}  here they used Deep learning models to predict the stock price movement and analyzed the accuracy of many models such as LSTM, CNN, RNN and many other nonlinear models. Also in \unskip~\cite{490201:11043816}  compared SVM, back propagation and LSTM and analyzed the accuracy.

In this model, we have compared LSTM model with and without Sliding window approach. LSTM was proposed back in 1997 by Felix Gers and his adviser J{\"{u}}rgen Schmidhuber and Fred Cummins who introduced the forget gate to deal with the vanishing gradient problem as stated in \unskip~\cite{490201:11043817}. LSTM is one of the most important model because of the introduction of forget gate and memory cell. In this model, the information flows through a mechanism known as cell states. Due to these memory cells now, LSTM selects and remember or forget things according to its importance. Therefore, LSTM can learn and identify patterns of data dynamically with time and produces huge prediction accuracy.  FA GersD, EckJ and Schmidhuber first used LSTM for time series forecasting long back in 2002 in \unskip~\cite{490201:11043818}.
    
\section{Methodology}
For Prediction of Stock Market, we need to deal with huge historical data that is highly nonlinear. To deal with this high non-linearity we need to find hidden pattern in our data and analyze them for prediction of future prices. Yet pattern identification given a nonlinear data is a trivial task and therefore there is a need of a dynamic model that could analyze our data and find all the hidden patterns. ANNs are very useful and capable of finding all the hidden patterns and exploiting the data to predict the future prices through self-learning process. These Neural networks are very efficient to predict the stock future prices and therefore are widely used. To predict a financial time series data Using Neural networks was introduced in \unskip~\cite{490201:11043819}. In this report, we have used Long Short Term Memory as a prediction model to predict the stock price of Netflix using Historical data of past 17 years from \BreakURLText{https://finance.yahoo.com/.}

In this report we have divided the prediction approach into subtopics and the subtopics are as follows:


\bgroup
\fixFloatSize{images/ff2d5313-9bc0-492d-8c3c-45f092930fcf-ustructure-of-this-paper1.jpg}
\begin{figure*}[!htbp]
\centering \makeatletter\IfFileExists{images/ff2d5313-9bc0-492d-8c3c-45f092930fcf-ustructure-of-this-paper1.jpg}{\includegraphics{images/ff2d5313-9bc0-492d-8c3c-45f092930fcf-ustructure-of-this-paper1.jpg}}{}
\makeatother 
\caption{{Structure of this paper}}
\label{f-ccbedd1c3cc3}
\end{figure*}
\egroup




\subsection{Data Gathering}In this work, 17 years of data of Netflix from March 2002 to March 2019 is used. All the data has been collected from \BreakURLText{https://finance.yahoo.com/}\textbf{\space }and downloaded under the historical data section. This Historical data is used to predict the future stock prices using LSTM Architecture.



\subsection{Data Processing}Before we train the LSTM model, we need to process the data. Processing is done by extracting some of the features from the stock price and normalizing the data.



\subsubsection{Feature Extraction}The historical data gathered was raw unprocessed data with high volatility. Prediction using this raw data is not a good option so first we need to process this data. Therefore, we have calculated technical indicators. Technical Indicators are the detailed study of past Market action for the purpose of forecasting future prices. It helps in forecasting the price direction and the current trend.

Some of the technical indicators which we used in this work are listed in Table~\ref{tw-8cac217298f9}
\begin{table}[!htbp]
\caption{{Technical Indicators} }
\label{tw-8cac217298f9}
\def\arraystretch{1}
\ignorespaces 
\centering 
\begin{tabulary}{\linewidth}{L}
\hline 
Technical Indicators\\
\tblmidrule 
Simple Moving Average - SMA\\
Exponential Moving Average - EMA\\
Triple Exponential Moving Average - TEMA\\
Kaufman's Adaptive Moving Average - KAMA\\
Moving Average Convergence/Divergence -MACD\\
Bollinger Bands\\
\%B\\
Relative Strength Index - RSI \\
 Average True Range - ATR\\
Chandelier Exit - CE\\
Chande Momentum Oscillator - CMO\\
Force Index - FI\\
Elder-ray\\
Stochastic \%k\\
Stochastic \%D\\
Williams \%R\\
Accumulation Distribution Oscillation - ADO\\
Commodity Channel Index - CCI\\
\tblbottomrule 
\end{tabulary}\par 
\end{table}




\subsubsection{Correlation}After extracting all these features we cannot use all these features in our model as not all features are relevant some of them are irrelevant and introduces noise in our model. Also, having redundant features confuses our model and therefore increases the computational time. Therefore, we only need to select those features that are related to our stock price, and we could discard other features.

The selection of features was based on the correlation coefficient value of all these features with the original stock's closing prices. The features with the highest correlation value was selected. The correlation techniques used over here where Scatter diagram and Pearson Correlation value.



\paragraph{Scatter Diagram}After extracting all these features we cannot use all these features in our model the as not all features are relevant some of them are irrelevant and introduces noise in our model. Also, having redundant features confuses our model and therefore increases the computational time. Therefore, we only need to select those features that are related to our stock price, and we could discard other features.

The selection of features was based on the correlation coefficient value of all these features with the original stock's closing prices. The features with the highest correlation value was selected. The correlation techniques used over here where Scatter diagram and Pearson Correlation value.

The scatter diagram for Simple moving Average and closing price of the data is shown inFigure~\ref{f-3c29855fadb4}


\bgroup
\fixFloatSize{images/3e4c774f-006a-4ee9-ba85-51801c340351-uscatter-diagram-ma14-days.png}
\begin{figure}[!htbp]
\centering \makeatletter\IfFileExists{images/3e4c774f-006a-4ee9-ba85-51801c340351-uscatter-diagram-ma14-days.png}{\includegraphics{images/3e4c774f-006a-4ee9-ba85-51801c340351-uscatter-diagram-ma14-days.png}}{}
\makeatother 
\caption{{Scatter Diagram for SMA for 14 days vs Close}}
\label{f-3c29855fadb4}
\end{figure}
\egroup




\paragraph{Pearson Correlation}Pearson Correlation gives a numerical response for finding the relation be- tween different data set. It assigns a number to the extent of relation between two data sets. Its value lies from -1 to 1, 1 representing exactly linear relation between two data sets and 0 representing no relation.

The formula for calculating Pearson correlation coefficient is Equation~(\ref{dfg-39a24d1cc108})
\let\saveeqnno\theequation
\let\savefrac\frac
\def\dispfrac{\displaystyle\savefrac}
\begin{eqnarray}
\let\frac\dispfrac
\gdef\theequation{1}
\let\theHequation\theequation
\label{dfg-39a24d1cc108}
\begin{array}{@{}l}r\;=\;\frac{\sum_{}((x\;-\;\overline x)(y\;-\;\overline y))}{\sqrt{{\displaystyle\sum_{}}(x\;-\;\overline x)^{2}{\displaystyle\sum_{}}(y\;-\;\overline y)^{2}}}\end{array}
\end{eqnarray}
\global\let\theequation\saveeqnno
\addtocounter{equation}{-1}\ignorespaces 
After analysis the Data using Pearson correlation and verifying using scatter diagram Simple moving average for 14 days was chosen as the parameter for the input for stock prediction for Netflix. A Simple moving average for 14 days of closing price of a stock is defined as the rolling average of closing price of the stocks over the last 14 days. A Simple Moving Average helps in smoothing out the curve which helps in reducing the volatility in the curve.



\subsubsection{Data Transformation}After getting the best feature, the next thing we do is data transformation. Data transformation is used to normalize the data and make the data stationary, which helps in pattern finding. Normalization helps improve convergence of the data. The data was transformed/mapped in the range 0 to 1.

After the data set is transformed into a clean data set, the data set is divided into training and testing sets to evaluate the prediction accuracy of my model. The training set is 95 percent of the total data set and the testing data is the rest of the data.
    
\section{Prediction Models}
In this work, we have implemented LSTM architecture and compared two different approaches with and without sliding window to understand which one performs better. LSTM was introduced to have long termed dependencies and deal with the vanishing gradient problem.



\subsection{LSTM without Sliding window Approach}The model was trained for 40 epochs and a batch size of 60. 60 days sliding window approach was used to predict the future trend. Initially the number of epochs were 100 and changed accordingly to build a good prediction model. This LSTM model was initialized of an input sequential layer lead by 4 LSTM layers each having neurons lesser than the previous and then finally a dense output layer with Adam optimizer and loss mean square error. The neural network design is shown in Figure~\ref{f-d4890a1b6b6b}.
\bgroup
\fixFloatSize{images/168f36c6-015d-4f38-9a7f-b3834427891f-uneural-network.jpg}
\begin{figure}[!htbp]
\centering \makeatletter\IfFileExists{images/168f36c6-015d-4f38-9a7f-b3834427891f-uneural-network.jpg}{\includegraphics{images/168f36c6-015d-4f38-9a7f-b3834427891f-uneural-network.jpg}}{}
\makeatother 
\caption{{Neural Network}}
\label{f-d4890a1b6b6b}
\end{figure}
\egroup




\subsection{LSTM without Sliding Window Approach}The input to this architecture is moving average of previous day and predicting the next day moving average. The Architecture of this LSTM model is same as the previous one with 40 epochs and a batch size of 60. Also, the network consist of one input layer with any sliding window This LSTM model was initialized of an input sequential layer lead by 4 LSTM layers each having neurons lesser than the previous and then finally a dense output layer with Adam optimizer and loss mean square error. The neural network design is same and shown in Figure~\ref{f-d4890a1b6b6b}.
    
\section{Experimental Result}
Root Mean Square Error (RMSE) is used to calculate the error for each model. 



\subsection{LSTM with Sliding window}The result for training and testing data is shown in Figure~\ref{f-3c51a19ee3af}Figure~\ref{f-0c23cbea0290} respectively. The RMSE for training and testing data is shown in Table~\ref{tw-b41c7f912268}.


\bgroup
\fixFloatSize{images/f6b29c6f-31c5-4d56-9d06-5e9acacfd7f1-u95-5-ma14-nflx-40-e-train.png}
\begin{figure}[!htbp]
\centering \makeatletter\IfFileExists{images/f6b29c6f-31c5-4d56-9d06-5e9acacfd7f1-u95-5-ma14-nflx-40-e-train.png}{\includegraphics{images/f6b29c6f-31c5-4d56-9d06-5e9acacfd7f1-u95-5-ma14-nflx-40-e-train.png}}{}
\makeatother 
\caption{{Result of LSTM model for Train data set}}
\label{f-3c51a19ee3af}
\end{figure}
\egroup

\bgroup
\fixFloatSize{images/4409e5a8-11b7-4bbe-8063-d3635e45a259-u95-5-ma14-nflx-40-e-test.png}
\begin{figure}[!htbp]
\centering \makeatletter\IfFileExists{images/4409e5a8-11b7-4bbe-8063-d3635e45a259-u95-5-ma14-nflx-40-e-test.png}{\includegraphics{images/4409e5a8-11b7-4bbe-8063-d3635e45a259-u95-5-ma14-nflx-40-e-test.png}}{}
\makeatother 
\caption{{Result of LSTM model for Test data set}}
\label{f-0c23cbea0290}
\end{figure}
\egroup

\begin{table}[!htbp]
\caption{{Epoch = 40, Feature input = MA14} }
\label{tw-b41c7f912268}
\def\arraystretch{1}
\ignorespaces 
\centering 
\begin{tabulary}{\linewidth}{LLL}
\hline 
Input & RMSE & Size\\
\tblmidrule 
Train &
  2.5983 &
  3934\\
Test &
  6.3923 &
  223\\
\tblbottomrule 
\end{tabulary}\par 
\end{table}




\subsection{LSTM without Sliding window}The result for training and testing data is shown in Figure~\ref{f-c277cf52a6fb}Figure~\ref{f-396ecc875a55} respectively. The RMSE for training and testing data is shown in Table~\ref{tw-03cba5150d1b}.


\bgroup
\fixFloatSize{images/2c07782a-1b01-4380-96a9-5610ce11cd14-u95-5-ma14-nflx-40-e-train-withou-sliding-window.png}
\begin{figure}[!htbp]
\centering \makeatletter\IfFileExists{images/2c07782a-1b01-4380-96a9-5610ce11cd14-u95-5-ma14-nflx-40-e-train-withou-sliding-window.png}{\includegraphics{images/2c07782a-1b01-4380-96a9-5610ce11cd14-u95-5-ma14-nflx-40-e-train-withou-sliding-window.png}}{}
\makeatother 
\caption{{Result of LSTM model for Train data set}}
\label{f-c277cf52a6fb}
\end{figure}
\egroup

\bgroup
\fixFloatSize{images/aca87a5a-3f19-4cf7-9668-18f938b4bedf-u95-5-ma14-nflx-40-e-test-withou-sliding-window.png}
\begin{figure}[!htbp]
\centering \makeatletter\IfFileExists{images/aca87a5a-3f19-4cf7-9668-18f938b4bedf-u95-5-ma14-nflx-40-e-test-withou-sliding-window.png}{\includegraphics{images/aca87a5a-3f19-4cf7-9668-18f938b4bedf-u95-5-ma14-nflx-40-e-test-withou-sliding-window.png}}{}
\makeatother 
\caption{{Result of LSTM model for Test data set}}
\label{f-396ecc875a55}
\end{figure}
\egroup

\begin{table}[!htbp]
\caption{{Epoch = 40, Feature input = MA14} }
\label{tw-03cba5150d1b}
\def\arraystretch{1}
\ignorespaces 
\centering 
\begin{tabulary}{\linewidth}{LLL}
\hline 
Input & RMSE & Size\\
\tblmidrule 
Train &
  2.8778 &
  3994\\
Test &
  3.5498 &
  211\\
\tblbottomrule 
\end{tabulary}\par 
\end{table}

    
\section{Conclusions}
In this work, we tried to compare two different approaches to understand which performs better. We predicted stocks of Netflix using Sliding window and without using sliding window and from the results it was clear that without using a sliding window gives better result compared to with using sliding window. Simple moving average for 14 days was used as an input parameter for both the approaches. We would like to highlight forecasting stock prices are very much helpful for investors to earn huge profit. Different methods are adopted to predict the future price. Predicting future price of a given stock to produce an accurate result is encouraging researchers to find some new technique to improve the accuracy. RNNs like LSTM are very good at processing sequential time series data. LSTM has been proven a very good solution while dealing with sequential data streams. In this work, we were able to produce significantly good result without using sliding window approach and LSTM architecture to predict the future price of Netflix stocks. 
    



\bibliographystyle{elsarticle-num}

\bibliography{\jobname}

\end{document}
